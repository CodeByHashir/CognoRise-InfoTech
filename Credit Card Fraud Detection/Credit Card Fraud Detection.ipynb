{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d669bce-6bae-4858-b9d1-16e0d479cd8b",
   "metadata": {},
   "source": [
    "# Handling Imbalanced Data with SMOTE\r\n",
    "\r\n",
    "In this notebook, we will explore how to handle imbalanced datasets using Synthetic Minority Over-sampling Technique (SMOTE). We will use a sample dataset and demonstrate how to apply SMOTE to balance the dataset. We will then train a Logistic Regression and a Decision Tree classifier and evaluate their performance.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827755ba-5e73-43d3-85dc-22f6eb2b5fa8",
   "metadata": {},
   "source": [
    "# Imports and Setup\n",
    "\n",
    "First, we will import the necessary libraries required for our analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51e5182-8ad9-4a84-bc20-ab311140264e",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0810773-b1aa-4d97-a7e4-93b27e46d5f3",
   "metadata": {},
   "source": [
    "# Loading the Data\r\n",
    "\r\n",
    "We will create a sample dataset to work with. In a real-world scenario, you would load your dataset from a file.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be8d0dcf-afb0-4526-b09f-53c103b9a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea71937-87e0-4a5d-bfab-5427a3749b10",
   "metadata": {},
   "source": [
    "# Data Preprocessing\r\n",
    "\r\n",
    "Before we apply any machine learning algorithms, we need to preprocess the data. This includes splitting the data into training and testing sets.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fca3e95-d393-499e-84d9-64f45de93dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aaf37ae-4112-4cdd-ba03-c2194ab32db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f59e7b-dbc2-44ea-bdd2-14bc97d145fc",
   "metadata": {},
   "source": [
    "\n",
    "### *As class dtype is int64, and class is basically which we need to predict. And this is Super bias machine learning problem*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94a6122f-1ec3-416e-aeb7-29fee1037189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9debae2-7817-4c68-9e5a-4814bb785c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0863d978-1775-4d76-8649-5172b8511f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e998a01-9423-47f6-a13a-d12a83d21dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f139f597-46b2-4170-b0e6-76f29a2557e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b69dc621-d7e9-4072-a0d3-2b0dd1b658ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['Amount'] = sc.fit_transform(pd.DataFrame(dataframe['Amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bd0b692-3436-424c-8126-1d29bb8b1b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.244964      0  \n",
       "1 -0.342475      0  \n",
       "2  1.160686      0  \n",
       "3  0.140534      0  \n",
       "4 -0.073403      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1030c56b-c135-4013-952a-d7fd0935f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop(['Time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d6a327e-b5ad-4d59-bd69-cb0926402d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "882ec549-b7df-4df6-b847-e336c61b0a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9144"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9902f00e-7b86-4d8e-9c31-3dbcb06545c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "948bf537-2d2e-4cf8-ba4e-88deacce6ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "413b26c2-2556-4dc6-85be-ff9c1b2c5785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    275190\n",
       "1       473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3bdc209-b54c-46cf-a088-cbb543c44b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.countplot(x='Class', data=dataframe)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d398c013-e65e-45ef-8cfd-54eef4838d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataframe.drop('Class' ,axis = 1)\n",
    "Y = dataframe['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f820a0-f0a9-4499-b257-f3e6261b8ba5",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation\r\n",
    "\r\n",
    "We will train a Logistic Regression and a Decision Tree classifier on the resampled data and evaluate their performance using accuracy and classification reports.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "953eb07f-12f8-4598-8082-94a1de51cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size= 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d163aa5-ef18-4f6a-8bcc-0e7cf059662f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============== Logistic Regression Model ================\n",
      "Accuracy: 0.9992\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     55042\n",
      "           1       0.89      0.60      0.72        91\n",
      "\n",
      "    accuracy                           1.00     55133\n",
      "   macro avg       0.94      0.80      0.86     55133\n",
      "weighted avg       1.00      1.00      1.00     55133\n",
      "\n",
      "\n",
      "============== Decision Tree Model ================\n",
      "Accuracy: 0.9990\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     55042\n",
      "           1       0.68      0.74      0.71        91\n",
      "\n",
      "    accuracy                           1.00     55133\n",
      "   macro avg       0.84      0.87      0.85     55133\n",
      "weighted avg       1.00      1.00      1.00     55133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    'Logistic Regression Model': LogisticRegression(),\n",
    "    'Decision Tree Model': DecisionTreeClassifier()\n",
    "}\n",
    "for name, clf, in classifiers.items():\n",
    "    print(f\"\\n============== {name} ================\")\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(Y_test, Y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bdeeaf-45a1-428f-9d45-258e1659714c",
   "metadata": {},
   "source": [
    "### Handling UnderSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b9cba5a-806d-4101-9197-5b7ca05b03dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = dataframe[dataframe['Class'] == 0]\n",
    "fraud = dataframe[dataframe['Class'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91b883e8-36e2-4feb-96aa-ee30152ff399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275190, 30)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bba53d3b-ddda-4572-b228-add69b13930a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b40a76b0-4107-4f81-8bae-a842fe9b9abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_sample = normal.sample(n=473)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ddbd054-8176-43cd-a5db-b74657195936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70c3e694-56bb-4528-a35c-2f6e5bc8b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe = pd.concat([normal_sample, fraud], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f26c287-05ba-452a-b24d-57fb58a69c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.024485</td>\n",
       "      <td>-2.304575</td>\n",
       "      <td>0.664199</td>\n",
       "      <td>-0.377223</td>\n",
       "      <td>-4.732620</td>\n",
       "      <td>3.498304</td>\n",
       "      <td>4.259654</td>\n",
       "      <td>-0.929751</td>\n",
       "      <td>-0.463516</td>\n",
       "      <td>0.160352</td>\n",
       "      <td>0.966000</td>\n",
       "      <td>-0.894350</td>\n",
       "      <td>-0.569458</td>\n",
       "      <td>-1.292733</td>\n",
       "      <td>-0.492253</td>\n",
       "      <td>0.795139</td>\n",
       "      <td>0.443073</td>\n",
       "      <td>-1.027526</td>\n",
       "      <td>1.903347</td>\n",
       "      <td>-0.689325</td>\n",
       "      <td>-0.398995</td>\n",
       "      <td>0.797191</td>\n",
       "      <td>1.046637</td>\n",
       "      <td>-0.234708</td>\n",
       "      <td>0.021939</td>\n",
       "      <td>-0.136160</td>\n",
       "      <td>0.509718</td>\n",
       "      <td>-0.818924</td>\n",
       "      <td>3.990132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.113273</td>\n",
       "      <td>0.009239</td>\n",
       "      <td>1.459956</td>\n",
       "      <td>-2.425584</td>\n",
       "      <td>-0.306915</td>\n",
       "      <td>1.001422</td>\n",
       "      <td>-0.792360</td>\n",
       "      <td>-1.951647</td>\n",
       "      <td>-1.812568</td>\n",
       "      <td>2.058314</td>\n",
       "      <td>0.455658</td>\n",
       "      <td>-0.875951</td>\n",
       "      <td>0.286120</td>\n",
       "      <td>-0.921312</td>\n",
       "      <td>-0.179043</td>\n",
       "      <td>-0.814295</td>\n",
       "      <td>0.370478</td>\n",
       "      <td>0.833310</td>\n",
       "      <td>1.335619</td>\n",
       "      <td>-0.469561</td>\n",
       "      <td>1.335553</td>\n",
       "      <td>-0.396542</td>\n",
       "      <td>-0.170665</td>\n",
       "      <td>0.189904</td>\n",
       "      <td>0.355006</td>\n",
       "      <td>0.019282</td>\n",
       "      <td>-0.680075</td>\n",
       "      <td>-0.381030</td>\n",
       "      <td>-0.329241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.128803</td>\n",
       "      <td>1.208838</td>\n",
       "      <td>-0.422170</td>\n",
       "      <td>-0.700690</td>\n",
       "      <td>0.947640</td>\n",
       "      <td>-0.502414</td>\n",
       "      <td>0.885474</td>\n",
       "      <td>0.032354</td>\n",
       "      <td>-0.214916</td>\n",
       "      <td>-0.382093</td>\n",
       "      <td>1.288553</td>\n",
       "      <td>0.949263</td>\n",
       "      <td>0.476740</td>\n",
       "      <td>-0.993781</td>\n",
       "      <td>-0.950736</td>\n",
       "      <td>0.385092</td>\n",
       "      <td>0.174135</td>\n",
       "      <td>0.062685</td>\n",
       "      <td>-0.090846</td>\n",
       "      <td>0.181032</td>\n",
       "      <td>-0.300325</td>\n",
       "      <td>-0.650364</td>\n",
       "      <td>0.103326</td>\n",
       "      <td>0.613327</td>\n",
       "      <td>-0.412486</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.332124</td>\n",
       "      <td>0.135630</td>\n",
       "      <td>-0.348072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.017600</td>\n",
       "      <td>-1.795668</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>-1.374096</td>\n",
       "      <td>-1.800480</td>\n",
       "      <td>-0.747904</td>\n",
       "      <td>-1.160132</td>\n",
       "      <td>-0.209514</td>\n",
       "      <td>-1.036741</td>\n",
       "      <td>1.448309</td>\n",
       "      <td>-0.930899</td>\n",
       "      <td>-0.488672</td>\n",
       "      <td>0.929604</td>\n",
       "      <td>-0.649289</td>\n",
       "      <td>0.041174</td>\n",
       "      <td>-0.232410</td>\n",
       "      <td>0.340505</td>\n",
       "      <td>-0.175012</td>\n",
       "      <td>-0.163076</td>\n",
       "      <td>-0.145443</td>\n",
       "      <td>-0.325438</td>\n",
       "      <td>-0.730680</td>\n",
       "      <td>0.340594</td>\n",
       "      <td>-0.077873</td>\n",
       "      <td>-0.636716</td>\n",
       "      <td>-0.497016</td>\n",
       "      <td>0.016133</td>\n",
       "      <td>-0.011945</td>\n",
       "      <td>0.220496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.650592</td>\n",
       "      <td>0.938051</td>\n",
       "      <td>2.172784</td>\n",
       "      <td>-0.547236</td>\n",
       "      <td>0.328015</td>\n",
       "      <td>-0.909602</td>\n",
       "      <td>1.096545</td>\n",
       "      <td>-0.335997</td>\n",
       "      <td>-0.510452</td>\n",
       "      <td>-0.640745</td>\n",
       "      <td>-0.322968</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>0.292822</td>\n",
       "      <td>-0.145062</td>\n",
       "      <td>0.465393</td>\n",
       "      <td>0.361362</td>\n",
       "      <td>-0.750422</td>\n",
       "      <td>-0.492744</td>\n",
       "      <td>-0.606313</td>\n",
       "      <td>0.005783</td>\n",
       "      <td>-0.254831</td>\n",
       "      <td>-0.669217</td>\n",
       "      <td>-0.227411</td>\n",
       "      <td>0.368938</td>\n",
       "      <td>0.203976</td>\n",
       "      <td>-0.018847</td>\n",
       "      <td>-0.175672</td>\n",
       "      <td>-0.161679</td>\n",
       "      <td>-0.348072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -2.024485 -2.304575  0.664199 -0.377223 -4.732620  3.498304  4.259654   \n",
       "1 -1.113273  0.009239  1.459956 -2.425584 -0.306915  1.001422 -0.792360   \n",
       "2 -0.128803  1.208838 -0.422170 -0.700690  0.947640 -0.502414  0.885474   \n",
       "3  2.017600 -1.795668 -0.465084 -1.374096 -1.800480 -0.747904 -1.160132   \n",
       "4 -0.650592  0.938051  2.172784 -0.547236  0.328015 -0.909602  1.096545   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0 -0.929751 -0.463516  0.160352  0.966000 -0.894350 -0.569458 -1.292733   \n",
       "1 -1.951647 -1.812568  2.058314  0.455658 -0.875951  0.286120 -0.921312   \n",
       "2  0.032354 -0.214916 -0.382093  1.288553  0.949263  0.476740 -0.993781   \n",
       "3 -0.209514 -1.036741  1.448309 -0.930899 -0.488672  0.929604 -0.649289   \n",
       "4 -0.335997 -0.510452 -0.640745 -0.322968  0.021663  0.292822 -0.145062   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0 -0.492253  0.795139  0.443073 -1.027526  1.903347 -0.689325 -0.398995   \n",
       "1 -0.179043 -0.814295  0.370478  0.833310  1.335619 -0.469561  1.335553   \n",
       "2 -0.950736  0.385092  0.174135  0.062685 -0.090846  0.181032 -0.300325   \n",
       "3  0.041174 -0.232410  0.340505 -0.175012 -0.163076 -0.145443 -0.325438   \n",
       "4  0.465393  0.361362 -0.750422 -0.492744 -0.606313  0.005783 -0.254831   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.797191  1.046637 -0.234708  0.021939 -0.136160  0.509718 -0.818924   \n",
       "1 -0.396542 -0.170665  0.189904  0.355006  0.019282 -0.680075 -0.381030   \n",
       "2 -0.650364  0.103326  0.613327 -0.412486  0.094972  0.332124  0.135630   \n",
       "3 -0.730680  0.340594 -0.077873 -0.636716 -0.497016  0.016133 -0.011945   \n",
       "4 -0.669217 -0.227411  0.368938  0.203976 -0.018847 -0.175672 -0.161679   \n",
       "\n",
       "     Amount  Class  \n",
       "0  3.990132      0  \n",
       "1 -0.329241      0  \n",
       "2 -0.348072      0  \n",
       "3  0.220496      0  \n",
       "4 -0.348072      0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9167ca47-2b3b-4ef9-b607-5b928e54a7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    473\n",
       "1    473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataframe['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad848587-856c-462d-9ab5-5b8eee40224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_dataframe.drop('Class', axis = 1)\n",
    "Y = new_dataframe['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1ba4098-8ca2-4d65-89f6-318d61e2eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size= 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "242337c9-705b-47c1-b0d4-75a922db3df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============== Logistic Regression Model ================\n",
      "Accuracy: 0.9579\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        88\n",
      "           1       1.00      0.92      0.96       102\n",
      "\n",
      "    accuracy                           0.96       190\n",
      "   macro avg       0.96      0.96      0.96       190\n",
      "weighted avg       0.96      0.96      0.96       190\n",
      "\n",
      "\n",
      "============== Decision Tree Model ================\n",
      "Accuracy: 0.9211\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91        88\n",
      "           1       0.92      0.93      0.93       102\n",
      "\n",
      "    accuracy                           0.92       190\n",
      "   macro avg       0.92      0.92      0.92       190\n",
      "weighted avg       0.92      0.92      0.92       190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    'Logistic Regression Model': LogisticRegression(),\n",
    "    'Decision Tree Model': DecisionTreeClassifier()\n",
    "}\n",
    "for name, clf, in classifiers.items():\n",
    "    print(f\"\\n============== {name} ================\")\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(Y_test, Y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f915dd7b-d635-4249-b5eb-cec8a626f0f4",
   "metadata": {},
   "source": [
    "### Working with Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a7631e0-db33-4162-b346-186faabc2105",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataframe.drop('Class', axis = 1)\n",
    "Y = dataframe['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b42165ca-4a35-42d6-9e2d-91edbb445af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663, 29)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cbd986ad-7afa-4d74-90c7-7cef9503a41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44fd38d-c057-4dda-9fed-ff394ca270aa",
   "metadata": {},
   "source": [
    "# Handling Imbalanced Data with SMOTE\n",
    "\n",
    "Since our dataset is balanced for demonstration purposes, let's simulate an imbalanced dataset and then apply SMOTE to balance it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d62aa48-1cb9-4171-bf48-193a7b095877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "778a29b1-e619-4cbd-b499-f0177d5830fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, Y_res = SMOTE().fit_resample(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f0ca6d83-33d0-4337-bfc1-4e8b067c5ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    275190\n",
       "1    275190\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "08144f73-72f6-4377-a0e3-bb07e9115aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_res, Y_res, test_size= 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "41cfe8e6-c42a-4c3b-98b6-a590762004f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============== Logistic Regression Model ================\n",
      "Accuracy: 0.9460\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95     55073\n",
      "           1       0.97      0.92      0.94     55003\n",
      "\n",
      "    accuracy                           0.95    110076\n",
      "   macro avg       0.95      0.95      0.95    110076\n",
      "weighted avg       0.95      0.95      0.95    110076\n",
      "\n",
      "\n",
      "============== Decision Tree Model ================\n",
      "Accuracy: 0.9982\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     55073\n",
      "           1       1.00      1.00      1.00     55003\n",
      "\n",
      "    accuracy                           1.00    110076\n",
      "   macro avg       1.00      1.00      1.00    110076\n",
      "weighted avg       1.00      1.00      1.00    110076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    'Logistic Regression Model': LogisticRegression(),\n",
    "    'Decision Tree Model': DecisionTreeClassifier()\n",
    "}\n",
    "for name, clf, in classifiers.items():\n",
    "    print(f\"\\n============== {name} ================\")\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(Y_test, Y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f65bfae-b24c-40c8-b7f7-c963050c2ce6",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how to handle imbalanced datasets using SMOTE. We applied SMOTE to balance the training data and trained two classifiers: Logistic Regression and Decision Tree. We evaluated their performance using accuracy and classification reports. Balancing the dataset with SMOTE helped improve the performance of the classifiers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a375af7-52d4-482d-8fe9-c95e0715beed",
   "metadata": {},
   "source": [
    "## Why SMOTE is Used\r\n",
    "\r\n",
    "When dealing with imbalanced datasets, where one class significantly outnumbers the other, machine learning models tend to be biased towards the majority class. This bias often results in poor performance, especially in predicting the minority class.\r\n",
    "\r\n",
    "### Challenges with Imbalanced Data\r\n",
    "- **Bias towards Majority Class**: Models trained on imbalanced data might predict the majority class more often, ignoring the minority class.\r\n",
    "- **Skewed Performance Metrics**: Common performance metrics like accuracy can be misleading. For example, in a dataset with 90% of instances belonging to one class, a model predicting only the majority class can achieve 90% accuracy but will perform poorly on the minority class.\r\n",
    "\r\n",
    "### Addressing Imbalance with SMOTE\r\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) is a powerful technique used to balance the dataset by generating synthetic examples for the minority class. It works by:\r\n",
    "1. **Selecting Minority Class Instances**: Randomly choosing instances from the minority class.\r\n",
    "2. **Generating Synthetic Samples**: Creating new synthetic samples by interpolating between the selected instances and their nearest neighbors.\r\n",
    "\r\n",
    "### Benefits of SMOTE\r\n",
    "- **Improved Model Performance**: Balancing the dataset helps models learn the decision boundary more effectively, improving their performance on both classes.\r\n",
    "- **Better Generalization**: Models trained on balanced datasets tend to generalize better to unseen data.\r\n",
    "- **Enhanced Metrics**: Using SMOTE can lead to more meaningful performance metrics, providing a clearer picture of the model's capabilities.\r\n",
    "\r\n",
    "In this notebook, we apply SMOTE to our imbalanced dataset before training our machine learning models to ensure a balanced representation of both classes.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e6400b-3cc8-43b5-bd1e-69c69bc87f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
